# ðŸš€ Big Data Testing Environment

A **production-ready, bulletproof Big Data testing environment** with guaranteed component compatibility and zero startup issues. Perfect for learning, development, and Big Data analysis coursework.

## ðŸŒŸ Features

### âœ… **Complete Big Data Stack**
- **Hadoop 3.3.4** (HDFS + YARN) - Latest stable version
- **Apache Spark 3.4.1** - Fully compatible with Hadoop 3.3.4
- **Apache Hive 3.1.3** - With PostgreSQL metastore (no Derby issues!)
- **Jupyter Lab** - Complete PySpark integration
- **PostgreSQL 13** - Reliable metastore database
- **Web UIs** - Service health and performance monitoring

### âœ… **Zero Configuration Hassles**
- **Proven compatibility matrix** - No version conflicts
- **PostgreSQL metastore** - Eliminates Derby connectivity issues
- **Automatic service dependencies** - Proper startup order
- **Health checks** - Comprehensive service monitoring
- **Windows automation** - Native batch scripts for all operations

### âœ… **Production-Ready Architecture**
- **Docker Compose orchestration** - 10 integrated services
- **Persistent data storage** - Named volumes for data durability
- **Optimized configurations** - Performance-tuned for development
- **Comprehensive logging** - Easy debugging and monitoring
- **Scalable design** - Ready for production workloads

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Jupyter Lab   â”‚    â”‚   Spark Master  â”‚    â”‚   Spark Worker  â”‚
â”‚   (Port 8888)   â”‚    â”‚   (Port 8080)   â”‚    â”‚   (Port 8081)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HiveServer2    â”‚    â”‚ Hive Metastore  â”‚    â”‚   PostgreSQL    â”‚
â”‚  (Port 10000)   â”‚    â”‚   (Port 9083)   â”‚    â”‚   (Port 5432)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ YARN ResourceMgrâ”‚    â”‚  Hadoop NameNodeâ”‚    â”‚ Hadoop DataNode â”‚
â”‚  (Port 8088)    â”‚    â”‚   (Port 9870)   â”‚    â”‚   (Port 9864)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  YARN NodeMgr   â”‚
                    â”‚  (Port 8042)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### Prerequisites
- **Docker Desktop** installed and running
- **8GB+ RAM** recommended
- **Windows 10/11** (scripts optimized for Windows)

### 1. Setup (One-time)
```bash
# Clone the repository
git clone https://github.com/hossamefia/BigDataEnv.git
cd BigDataEnv

# Run initial setup
scripts\setup.bat
```

### 2. Start Environment
```bash
# Start all services (takes 2-3 minutes)
scripts\start.bat
```

### 3. Validate Installation
```bash
# Check all services are healthy
scripts\validate.bat
```

### 4. Access Services
- **ðŸ“Š Jupyter Lab**: http://localhost:8888 (token: `bigdata123`)
- **ðŸ—„ï¸ Hadoop NameNode**: http://localhost:9870
- **ðŸ“ˆ YARN ResourceManager**: http://localhost:8088
- **âš¡ Spark Master**: http://localhost:8080
- **ðŸ” HiveServer2 UI**: http://localhost:10002

## ðŸ“š Learning Path

### 1. **Start with Hadoop Basics**
Open `notebooks/01-hadoop-basics.ipynb` to learn:
- HDFS operations and file management
- Distributed storage concepts
- Data upload and retrieval

### 2. **Master Spark Fundamentals**
Explore `notebooks/02-spark-intro.ipynb` for:
- Spark DataFrame operations
- Data transformations and actions
- SQL queries and analytics

### 3. **Database with Hive SQL**
Work through `notebooks/03-hive-sql.ipynb` to understand:
- Data warehousing concepts
- SQL queries on big data
- Hive-Spark integration

### 4. **Full Stack Integration**
Complete `notebooks/04-integration.ipynb` for:
- End-to-end data pipelines
- Advanced analytics
- Production workflows

## ðŸ› ï¸ Management Scripts

| Script | Purpose | Usage |
|--------|---------|-------|
| `setup.bat` | Initial environment setup | Run once after cloning |
| `start.bat` | Start all services | Daily startup |
| `stop.bat` | Graceful shutdown | End of session |
| `validate.bat` | Health check all services | Troubleshooting |
| `monitor.bat` | View logs and status | Service monitoring |
| `cleanup.bat` | Complete reset | When issues occur |

## ðŸ“Š Sample Data Included

The environment comes with realistic sample datasets:

### ðŸ‘¥ Users Dataset (`data/samples/users.csv`)
- 20 sample users with demographics
- Countries across continents
- Age ranges for segmentation analysis

### ðŸ’³ Transactions Dataset (`data/samples/transactions.json`)
- E-commerce transaction data
- Multiple currencies and merchants
- Various transaction states

### ðŸ“ Log Data (`data/samples/logs.txt`)
- Application log samples
- Structured log format for parsing
- Timestamp and severity levels

## ðŸ”§ Troubleshooting

### Common Issues & Solutions

#### ðŸ³ Docker Issues
```bash
# Docker not running
# â–º Start Docker Desktop and try again

# Insufficient memory
# â–º Increase Docker memory limit to 8GB+
```

#### ðŸ”— Service Connection Issues
```bash
# Services not starting
scripts\stop.bat
scripts\start.bat

# Port conflicts
# â–º Check if ports 5432, 8080, 8888, 9870 are free
```

#### ðŸ’¾ Data Issues
```bash
# Clean start needed
scripts\cleanup.bat
scripts\setup.bat
scripts\start.bat
```

### ðŸ†˜ Getting Help
1. Check service logs: `scripts\monitor.bat`
2. Validate health: `scripts\validate.bat`
3. Review `docs/troubleshooting.md` for detailed solutions
4. Open an issue on GitHub

## ðŸ“ Project Structure

```
BigDataEnv/
â”œâ”€â”€ ðŸ“„ README.md                 # This file
â”œâ”€â”€ ðŸ³ docker-compose.yml        # Service orchestration
â”œâ”€â”€ ðŸ“ configs/                  # Configuration files
â”‚   â”œâ”€â”€ ðŸ“ hadoop/              # Hadoop configurations
â”‚   â”œâ”€â”€ ðŸ“ hive/                # Hive configurations  
â”‚   â”œâ”€â”€ ðŸ“ spark/               # Spark configurations
â”‚   â””â”€â”€ ðŸ“ jupyter/             # Jupyter configurations
â”œâ”€â”€ ðŸ“ scripts/                  # Windows automation
â”‚   â”œâ”€â”€ ðŸš€ setup.bat            # Initial setup
â”‚   â”œâ”€â”€ â–¶ï¸ start.bat             # Start services
â”‚   â”œâ”€â”€ â¸ï¸ stop.bat              # Stop services
â”‚   â”œâ”€â”€ âœ… validate.bat          # Health checks
â”‚   â”œâ”€â”€ ðŸ“Š monitor.bat           # Service monitoring
â”‚   â””â”€â”€ ðŸ§¹ cleanup.bat          # Reset environment
â”œâ”€â”€ ðŸ“ notebooks/                # Jupyter notebooks
â”‚   â”œâ”€â”€ ðŸ““ 01-hadoop-basics.ipynb
â”‚   â”œâ”€â”€ ðŸ““ 02-spark-intro.ipynb
â”‚   â”œâ”€â”€ ðŸ““ 03-hive-sql.ipynb
â”‚   â””â”€â”€ ðŸ““ 04-integration.ipynb
â”œâ”€â”€ ðŸ“ data/samples/             # Sample datasets
â”‚   â”œâ”€â”€ ðŸ‘¥ users.csv
â”‚   â”œâ”€â”€ ðŸ’³ transactions.json
â”‚   â””â”€â”€ ðŸ“ logs.txt
â””â”€â”€ ðŸ“ docs/                     # Documentation
    â”œâ”€â”€ ðŸ“– setup-guide.md
    â”œâ”€â”€ ðŸ”§ troubleshooting.md
    â”œâ”€â”€ ðŸ—ï¸ architecture.md
    â””â”€â”€ âš¡ performance-tuning.md
```

## ðŸŽ¯ Use Cases

### ðŸŽ“ **Educational**
- **Big Data coursework** - Complete learning environment
- **Technology exploration** - Try different big data tools
- **Proof of concepts** - Test ideas without infrastructure

### ðŸ’¼ **Professional Development**
- **Skill building** - Hands-on experience with industry tools
- **Interview preparation** - Practice with real scenarios
- **Certification prep** - Cloudera, Databricks, AWS certifications

### ðŸ¢ **Enterprise Testing**
- **Data pipeline development** - Test ETL processes
- **Query optimization** - Performance tuning experiments
- **Integration testing** - Multi-component workflows

## ðŸ”’ Security Notes

This environment is configured for **development and learning**:
- Authentication is disabled for ease of use
- Default passwords are used
- Network security is minimal

**ðŸš¨ Do not use in production without proper security hardening!**

## ðŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. **Fork** the repository
2. **Create** a feature branch
3. **Test** your changes thoroughly
4. **Submit** a pull request

Areas where help is needed:
- Additional sample datasets
- More learning notebooks
- Performance optimizations
- Documentation improvements

## ðŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- **Apache Software Foundation** for the amazing big data tools
- **Docker** for containerization technology
- **PostgreSQL** team for the robust database
- **Jupyter** project for the excellent notebook environment

## ðŸ“ž Support

- **ðŸ“š Documentation**: Check the `docs/` folder
- **ðŸ› Issues**: Open a GitHub issue
- **ðŸ’¬ Discussions**: Use GitHub Discussions
- **ðŸ“§ Email**: For enterprise support inquiries

---

## ðŸŽ‰ Success Stories

> *"This environment saved me hours of configuration headaches. I was able to focus on learning Big Data concepts instead of fighting with setup issues."* - Data Science Student

> *"Perfect for our team's Big Data training program. Everyone had the same working environment in minutes."* - Enterprise Training Manager

> *"Finally, a Big Data stack that just works! Great for prototyping and proof of concepts."* - Data Engineer

---

**ðŸš€ Ready to dive into Big Data? Run `scripts\setup.bat` and start your journey!**